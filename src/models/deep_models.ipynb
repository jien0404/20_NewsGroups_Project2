{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from src.feature_engineering import tfidf_vectorize_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định thư mục gốc của dự án (từ notebook)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # Đi lên hai cấp từ notebooks/\n",
    "\n",
    "# Định nghĩa đường dẫn dữ liệu\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data/processed\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results/tables\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models/deep_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(DATA_DIR, \"val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector hóa văn bản bằng TF-IDF (dùng tập train để fit vectorizer)\n",
    "X_train, vectorizer = tfidf_vectorize_ngrams(train_df['clean_text'])\n",
    "y_train = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra xem y_train có chứa giá trị NaN không\n",
    "if y_train.isna().any():\n",
    "    print(f\"Cảnh báo: Tìm thấy {y_train.isna().sum()} giá trị NaN trong nhãn tập train\")\n",
    "    # Xử lý theo cách phù hợp với bài toán, ví dụ: loại bỏ hoặc gán nhãn mặc định\n",
    "    # KHÔNG sử dụng fillna(0) vì có thể gây nhầm lẫn với nhãn 0\n",
    "    # Dưới đây là cách loại bỏ các hàng có nhãn NaN\n",
    "    valid_indices = ~y_train.isna()\n",
    "    X_train = X_train[valid_indices]\n",
    "    y_train = y_train[valid_indices]\n",
    "\n",
    "X_val = vectorizer.transform(val_df['clean_text'])\n",
    "y_val = val_df['label']\n",
    "if y_val.isna().any():\n",
    "    valid_indices = ~y_val.isna()\n",
    "    X_val = X_val[valid_indices]\n",
    "    y_val = y_val[valid_indices]\n",
    "\n",
    "X_test = vectorizer.transform(test_df['clean_text'])\n",
    "y_test = test_df['label']\n",
    "if y_test.isna().any():\n",
    "    valid_indices = ~y_test.isna()\n",
    "    X_test = X_test[valid_indices]\n",
    "    y_test = y_test[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã chuyển đổi nhãn từ ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
      " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
      " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
      " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
      " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
      " 'talk.politics.misc' 'talk.religion.misc'] thành [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra xem các nhãn đã được chuyển đổi thành số chưa\n",
    "if not np.issubdtype(y_train.dtype, np.number):\n",
    "    # Chuyển đổi nhãn thành số nếu chưa phải\n",
    "    # Nên sử dụng một encoder để đảm bảo nhất quán\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_val = encoder.transform(y_val)\n",
    "    y_test = encoder.transform(y_test)\n",
    "    \n",
    "    # Lưu encoder để sử dụng sau này\n",
    "    joblib.dump(encoder, os.path.join(MODEL_DIR, \"label_encoder.pkl\"))\n",
    "    print(f\"Đã chuyển đổi nhãn từ {encoder.classes_} thành {list(range(len(encoder.classes_)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lớp nhãn: 20\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi dữ liệu thành tensor\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.toarray(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(set(y_train))\n",
    "print(f\"Số lớp nhãn: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mô hình MLP\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout_rate=0.5, output_dim=num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Thêm dropout để giảm overfitting\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Áp dụng dropout\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mô hình CNN được điều chỉnh cho dữ liệu TF-IDF\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=num_classes, num_filters=100, dropout_rate=0.5):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        # Sử dụng MLP với nhiều lớp hidden thay vì CNN\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Không sử dụng unsqueeze vì dữ liệu TF-IDF không có cấu trúc không gian\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mô hình RNN được điều chỉnh cho dữ liệu TF-IDF\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, output_dim=num_classes, dropout_rate=0.5):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        # Sử dụng MLP nhiều lớp thay vì LSTM\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Không sử dụng unsqueeze vì dữ liệu TF-IDF không có cấu trúc tuần tự\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm huấn luyện với early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, patience=3):\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Huấn luyện\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        # Đánh giá trên tập validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                total_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predicted.cpu().numpy())\n",
    "                val_true_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Kiểm tra early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"Lưu mô hình tốt nhất với Val Loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"Không cải thiện: {epochs_no_improve}/{patience}\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping sau {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Khôi phục mô hình tốt nhất\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    # zero_division=0 để tránh lỗi khi một lớp không có mẫu nào\n",
    "    report = classification_report(true_labels, predictions, output_dict=True, zero_division=0)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    # In confusion matrix để phân tích chi tiết\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return accuracy, report, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm lưu kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model_name, accuracy, report, val_accuracy, val_report, results_dir):\n",
    "    results = {\n",
    "        \"Model\": model_name,\n",
    "        \"Test_Accuracy\": accuracy,\n",
    "        \"Test_Precision\": report['weighted avg']['precision'],\n",
    "        \"Test_Recall\": report['weighted avg']['recall'],\n",
    "        \"Test_F1-Score\": report['weighted avg']['f1-score'],\n",
    "        \"Val_Accuracy\": val_accuracy,\n",
    "        \"Val_Precision\": val_report['weighted avg']['precision'],\n",
    "        \"Val_Recall\": val_report['weighted avg']['recall'],\n",
    "        \"Val_F1-Score\": val_report['weighted avg']['f1-score']\n",
    "    }\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_file = os.path.join(results_dir, \"deep_models_results.csv\")\n",
    "\n",
    "    # Check if the file exists. If not, create a new file with headers.\n",
    "    if not os.path.exists(results_file):\n",
    "        results_df.to_csv(results_file, index=False, header=True)\n",
    "    else:\n",
    "        results_df.to_csv(results_file, index=False, header=False, mode='a')  # Append without headers\n",
    "\n",
    "    print(f\"{model_name} results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm chính để huấn luyện và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, train_loader, val_loader, test_loader, num_epochs=0, learning_rate=0.001, patience=3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # Thêm L2 regularization\n",
    "\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=num_epochs, patience=patience)\n",
    "\n",
    "    print(f\"Evaluating {model_name} on validation set...\")\n",
    "    val_accuracy, val_report, val_avg_loss = evaluate_model(model, val_loader, criterion)\n",
    "    print(f\"{model_name} - Val Loss: {val_avg_loss:.4f}\")\n",
    "    print(f\"{model_name} - Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"Evaluating {model_name} on test set...\")\n",
    "    test_accuracy, test_report, test_avg_loss = evaluate_model(model, test_loader, criterion)\n",
    "    print(f\"{model_name} - Test Loss: {test_avg_loss:.4f}\")\n",
    "    print(f\"{model_name} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Lưu mô hình\n",
    "    model_path = os.path.join(MODEL_DIR, f\"{model_name}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"{model_name} saved to: {model_path}\")\n",
    "\n",
    "    # Lưu kết quả\n",
    "    save_results(model_name, test_accuracy, test_report, val_accuracy, val_report, RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khởi tạo và huấn luyện các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước đầu vào (số features TF-IDF): 5000\n",
      "Số lượng lớp: 20\n",
      "Kích thước tập train: 15997\n",
      "Kích thước tập validation: 2000\n",
      "Kích thước tập test: 2000\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "print(f\"Kích thước đầu vào (số features TF-IDF): {input_size}\")\n",
    "print(f\"Số lượng lớp: {num_classes}\")\n",
    "print(f\"Kích thước tập train: {len(train_dataset)}\")\n",
    "print(f\"Kích thước tập validation: {len(val_dataset)}\")\n",
    "print(f\"Kích thước tập test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLPClassifier...\n",
      "Epoch 1/15, Train Loss: 1.3899, Val Loss: 0.3263, Val Accuracy: 0.9615\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.3263\n",
      "Epoch 2/15, Train Loss: 0.2506, Val Loss: 0.1481, Val Accuracy: 0.9655\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1481\n",
      "Epoch 3/15, Train Loss: 0.1408, Val Loss: 0.1153, Val Accuracy: 0.9610\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1153\n",
      "Epoch 4/15, Train Loss: 0.1049, Val Loss: 0.1059, Val Accuracy: 0.9615\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1059\n",
      "Epoch 5/15, Train Loss: 0.0895, Val Loss: 0.1046, Val Accuracy: 0.9595\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1046\n",
      "Epoch 6/15, Train Loss: 0.0771, Val Loss: 0.1027, Val Accuracy: 0.9570\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1027\n",
      "Epoch 7/15, Train Loss: 0.0705, Val Loss: 0.1057, Val Accuracy: 0.9540\n",
      "Không cải thiện: 1/3\n",
      "Epoch 8/15, Train Loss: 0.0662, Val Loss: 0.1077, Val Accuracy: 0.9515\n",
      "Không cải thiện: 2/3\n",
      "Epoch 9/15, Train Loss: 0.0663, Val Loss: 0.1081, Val Accuracy: 0.9495\n",
      "Không cải thiện: 3/3\n",
      "Early stopping sau 9 epochs\n",
      "Evaluating MLPClassifier on validation set...\n",
      "Confusion Matrix:\n",
      "[[ 75   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0  24]\n",
      " [  0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  99   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1  96   1   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  98   1   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1  99   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94   0\n",
      "    4   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  93\n",
      "    7   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   1\n",
      "   82  13]\n",
      " [ 15   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5   1\n",
      "   13  65]]\n",
      "MLPClassifier - Val Loss: 0.1081\n",
      "MLPClassifier - Val Accuracy: 0.9495\n",
      "Evaluating MLPClassifier on test set...\n",
      "Confusion Matrix:\n",
      "[[ 84   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1  15]\n",
      " [  0  99   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  96   1   0   1   1   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  99   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0  99   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  98   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0  99   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  99   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0  93   0\n",
      "    2   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   3\n",
      "   78  14]\n",
      " [ 23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   15  59]]\n",
      "MLPClassifier - Test Loss: 0.1078\n",
      "MLPClassifier - Test Accuracy: 0.9485\n",
      "MLPClassifier saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\models/deep_learning\\MLPClassifier.pth\n",
      "MLPClassifier results saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\results/tables\\deep_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện và đánh giá MLP\n",
    "mlp_model = MLPClassifier(input_size, hidden_dim=128, dropout_rate=0.5, output_dim=num_classes)\n",
    "train_and_evaluate(mlp_model, \"MLPClassifier\", train_loader, val_loader, test_loader, num_epochs=15, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNNClassifier...\n",
      "Epoch 1/15, Train Loss: 1.1876, Val Loss: 0.1673, Val Accuracy: 0.9530\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1673\n",
      "Epoch 2/15, Train Loss: 0.1942, Val Loss: 0.1134, Val Accuracy: 0.9600\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1134\n",
      "Epoch 3/15, Train Loss: 0.1331, Val Loss: 0.0969, Val Accuracy: 0.9575\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.0969\n",
      "Epoch 4/15, Train Loss: 0.1049, Val Loss: 0.0965, Val Accuracy: 0.9570\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.0965\n",
      "Epoch 5/15, Train Loss: 0.0947, Val Loss: 0.0964, Val Accuracy: 0.9580\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.0964\n",
      "Epoch 6/15, Train Loss: 0.0857, Val Loss: 0.1061, Val Accuracy: 0.9535\n",
      "Không cải thiện: 1/3\n",
      "Epoch 7/15, Train Loss: 0.0751, Val Loss: 0.1010, Val Accuracy: 0.9570\n",
      "Không cải thiện: 2/3\n",
      "Epoch 8/15, Train Loss: 0.0733, Val Loss: 0.1031, Val Accuracy: 0.9545\n",
      "Không cải thiện: 3/3\n",
      "Early stopping sau 8 epochs\n",
      "Evaluating CNNClassifier on validation set...\n",
      "Confusion Matrix:\n",
      "[[ 83   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0  16]\n",
      " [  0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1  96   1   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  98   1   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1  99   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  99   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  95   0\n",
      "    4   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   1\n",
      "   88   7]\n",
      " [ 19   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5   1\n",
      "   15  59]]\n",
      "CNNClassifier - Val Loss: 0.1031\n",
      "CNNClassifier - Val Accuracy: 0.9545\n",
      "Evaluating CNNClassifier on test set...\n",
      "Confusion Matrix:\n",
      "[[ 86   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1  13]\n",
      " [  0  98   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  96   1   0   1   1   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  99   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1  99   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0  99   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  98   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0  99   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0  95   0\n",
      "    2   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  97\n",
      "    3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   3\n",
      "   84   8]\n",
      " [ 28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   19  50]]\n",
      "CNNClassifier - Test Loss: 0.0952\n",
      "CNNClassifier - Test Accuracy: 0.9495\n",
      "CNNClassifier saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\models/deep_learning\\CNNClassifier.pth\n",
      "CNNClassifier results saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\results/tables\\deep_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện và đánh giá \"CNN\" (thực chất là MLP nhiều lớp)\n",
    "cnn_model = CNNClassifier(input_size, output_dim=num_classes, dropout_rate=0.5)\n",
    "train_and_evaluate(cnn_model, \"CNNClassifier\", train_loader, val_loader, test_loader, num_epochs=15, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNNClassifier...\n",
      "Epoch 1/15, Train Loss: 1.1845, Val Loss: 0.1622, Val Accuracy: 0.9645\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1622\n",
      "Epoch 2/15, Train Loss: 0.2028, Val Loss: 0.1036, Val Accuracy: 0.9635\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1036\n",
      "Epoch 3/15, Train Loss: 0.1292, Val Loss: 0.0978, Val Accuracy: 0.9585\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.0978\n",
      "Epoch 4/15, Train Loss: 0.1052, Val Loss: 0.0975, Val Accuracy: 0.9555\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.0975\n",
      "Epoch 5/15, Train Loss: 0.0930, Val Loss: 0.1001, Val Accuracy: 0.9620\n",
      "Không cải thiện: 1/3\n",
      "Epoch 6/15, Train Loss: 0.0857, Val Loss: 0.1073, Val Accuracy: 0.9560\n",
      "Không cải thiện: 2/3\n",
      "Epoch 7/15, Train Loss: 0.0793, Val Loss: 0.1023, Val Accuracy: 0.9540\n",
      "Không cải thiện: 3/3\n",
      "Early stopping sau 7 epochs\n",
      "Evaluating RNNClassifier on validation set...\n",
      "Confusion Matrix:\n",
      "[[ 73   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0  26]\n",
      " [  0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1  97   1   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  98   1   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2  98   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  93   1\n",
      "    3   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  92\n",
      "    8   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   1\n",
      "   88   8]\n",
      " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5   1\n",
      "   15  71]]\n",
      "RNNClassifier - Val Loss: 0.1023\n",
      "RNNClassifier - Val Accuracy: 0.9540\n",
      "Evaluating RNNClassifier on test set...\n",
      "Confusion Matrix:\n",
      "[[ 82   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1  17]\n",
      " [  0  98   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  96   1   0   1   1   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  99   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1  99   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0  99   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  98   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  99   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0  92   0\n",
      "    2   4]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   3\n",
      "   78  14]\n",
      " [ 10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   16  71]]\n",
      "RNNClassifier - Test Loss: 0.1031\n",
      "RNNClassifier - Test Accuracy: 0.9520\n",
      "RNNClassifier saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\models/deep_learning\\RNNClassifier.pth\n",
      "RNNClassifier results saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\results/tables\\deep_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện và đánh giá \"RNN\" (thực chất là MLP nhiều lớp)\n",
    "rnn_model = RNNClassifier(input_size, output_dim=num_classes, dropout_rate=0.5)\n",
    "train_and_evaluate(rnn_model, \"RNNClassifier\", train_loader, val_loader, test_loader, num_epochs=15, patience=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
