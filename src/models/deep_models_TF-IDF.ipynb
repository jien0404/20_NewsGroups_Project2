{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from src.feature_engineering import tfidf_vectorize_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định thư mục gốc của dự án (từ notebook)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # Đi lên hai cấp từ notebooks/\n",
    "\n",
    "# Định nghĩa đường dẫn dữ liệu\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data/processed\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results/tables\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models/deep_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(DATA_DIR, \"val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector hóa văn bản bằng TF-IDF (dùng tập train để fit vectorizer)\n",
    "X_train, vectorizer = tfidf_vectorize_ngrams(train_df['clean_text'])\n",
    "y_train = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra xem y_train có chứa giá trị NaN không\n",
    "if y_train.isna().any():\n",
    "    print(f\"Cảnh báo: Tìm thấy {y_train.isna().sum()} giá trị NaN trong nhãn tập train\")\n",
    "    # Xử lý theo cách phù hợp với bài toán, ví dụ: loại bỏ hoặc gán nhãn mặc định\n",
    "    # KHÔNG sử dụng fillna(0) vì có thể gây nhầm lẫn với nhãn 0\n",
    "    # Dưới đây là cách loại bỏ các hàng có nhãn NaN\n",
    "    valid_indices = ~y_train.isna()\n",
    "    X_train = X_train[valid_indices]\n",
    "    y_train = y_train[valid_indices]\n",
    "\n",
    "X_val = vectorizer.transform(val_df['clean_text'])\n",
    "y_val = val_df['label']\n",
    "if y_val.isna().any():\n",
    "    valid_indices = ~y_val.isna()\n",
    "    X_val = X_val[valid_indices]\n",
    "    y_val = y_val[valid_indices]\n",
    "\n",
    "X_test = vectorizer.transform(test_df['clean_text'])\n",
    "y_test = test_df['label']\n",
    "if y_test.isna().any():\n",
    "    valid_indices = ~y_test.isna()\n",
    "    X_test = X_test[valid_indices]\n",
    "    y_test = y_test[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã chuyển đổi nhãn từ ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
      " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
      " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
      " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
      " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
      " 'talk.politics.misc' 'talk.religion.misc'] thành [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra xem các nhãn đã được chuyển đổi thành số chưa\n",
    "if not np.issubdtype(y_train.dtype, np.number):\n",
    "    # Chuyển đổi nhãn thành số nếu chưa phải\n",
    "    # Nên sử dụng một encoder để đảm bảo nhất quán\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_val = encoder.transform(y_val)\n",
    "    y_test = encoder.transform(y_test)\n",
    "    \n",
    "    # Lưu encoder để sử dụng sau này\n",
    "    joblib.dump(encoder, os.path.join(MODEL_DIR, \"label_encoder.pkl\"))\n",
    "    print(f\"Đã chuyển đổi nhãn từ {encoder.classes_} thành {list(range(len(encoder.classes_)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lớp nhãn: 20\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi dữ liệu thành tensor\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.toarray(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(set(y_train))\n",
    "print(f\"Số lớp nhãn: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mô hình MLP\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout_rate=0.5, output_dim=num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Thêm dropout để giảm overfitting\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Áp dụng dropout\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierVariant(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=256, hidden_dim2=128, dropout_rate=0.3, output_dim=num_classes):\n",
    "        super(MLPClassifierVariant, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)  # Batch Normalization\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm huấn luyện với early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, patience=3):\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Huấn luyện\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        # Đánh giá trên tập validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                total_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predicted.cpu().numpy())\n",
    "                val_true_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Kiểm tra early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"Lưu mô hình tốt nhất với Val Loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"Không cải thiện: {epochs_no_improve}/{patience}\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping sau {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Khôi phục mô hình tốt nhất\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    # zero_division=0 để tránh lỗi khi một lớp không có mẫu nào\n",
    "    report = classification_report(true_labels, predictions, output_dict=True, zero_division=0)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    # In confusion matrix để phân tích chi tiết\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return accuracy, report, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm lưu kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model_name, accuracy, report, val_accuracy, val_report, results_dir):\n",
    "    results = {\n",
    "        \"Model\": model_name,\n",
    "        \"Test_Accuracy\": accuracy,\n",
    "        \"Test_Precision\": report['weighted avg']['precision'],\n",
    "        \"Test_Recall\": report['weighted avg']['recall'],\n",
    "        \"Test_F1-Score\": report['weighted avg']['f1-score'],\n",
    "        \"Val_Accuracy\": val_accuracy,\n",
    "        \"Val_Precision\": val_report['weighted avg']['precision'],\n",
    "        \"Val_Recall\": val_report['weighted avg']['recall'],\n",
    "        \"Val_F1-Score\": val_report['weighted avg']['f1-score']\n",
    "    }\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_file = os.path.join(results_dir, \"deep_models_results.csv\")\n",
    "\n",
    "    # Check if the file exists. If not, create a new file with headers.\n",
    "    if not os.path.exists(results_file):\n",
    "        results_df.to_csv(results_file, index=False, header=True)\n",
    "    else:\n",
    "        results_df.to_csv(results_file, index=False, header=False, mode='a')  # Append without headers\n",
    "\n",
    "    print(f\"{model_name} results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm chính để huấn luyện và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, train_loader, val_loader, test_loader, num_epochs=0, learning_rate=0.001, patience=3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # Thêm L2 regularization\n",
    "\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=num_epochs, patience=patience)\n",
    "\n",
    "    print(f\"Evaluating {model_name} on validation set...\")\n",
    "    val_accuracy, val_report, val_avg_loss = evaluate_model(model, val_loader, criterion)\n",
    "    print(f\"{model_name} - Val Loss: {val_avg_loss:.4f}\")\n",
    "    print(f\"{model_name} - Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"Evaluating {model_name} on test set...\")\n",
    "    test_accuracy, test_report, test_avg_loss = evaluate_model(model, test_loader, criterion)\n",
    "    print(f\"{model_name} - Test Loss: {test_avg_loss:.4f}\")\n",
    "    print(f\"{model_name} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Lưu mô hình\n",
    "    model_path = os.path.join(MODEL_DIR, f\"{model_name}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"{model_name} saved to: {model_path}\")\n",
    "\n",
    "    # Lưu kết quả\n",
    "    save_results(model_name, test_accuracy, test_report, val_accuracy, val_report, RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khởi tạo và huấn luyện các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước đầu vào (số features TF-IDF): 5000\n",
      "Số lượng lớp: 20\n",
      "Kích thước tập train: 15997\n",
      "Kích thước tập validation: 2000\n",
      "Kích thước tập test: 2000\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "print(f\"Kích thước đầu vào (số features TF-IDF): {input_size}\")\n",
    "print(f\"Số lượng lớp: {num_classes}\")\n",
    "print(f\"Kích thước tập train: {len(train_dataset)}\")\n",
    "print(f\"Kích thước tập validation: {len(val_dataset)}\")\n",
    "print(f\"Kích thước tập test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLPClassifier_TF-IDF...\n",
      "Epoch 1/15, Train Loss: 1.3949, Val Loss: 0.3261, Val Accuracy: 0.9610\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.3261\n",
      "Epoch 2/15, Train Loss: 0.2447, Val Loss: 0.1469, Val Accuracy: 0.9610\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1469\n",
      "Epoch 3/15, Train Loss: 0.1401, Val Loss: 0.1183, Val Accuracy: 0.9605\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1183\n",
      "Epoch 4/15, Train Loss: 0.1055, Val Loss: 0.1069, Val Accuracy: 0.9590\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1069\n",
      "Epoch 5/15, Train Loss: 0.0891, Val Loss: 0.1036, Val Accuracy: 0.9595\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1036\n",
      "Epoch 6/15, Train Loss: 0.0771, Val Loss: 0.1029, Val Accuracy: 0.9565\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1029\n",
      "Epoch 7/15, Train Loss: 0.0712, Val Loss: 0.1049, Val Accuracy: 0.9535\n",
      "Không cải thiện: 1/3\n",
      "Epoch 8/15, Train Loss: 0.0672, Val Loss: 0.1055, Val Accuracy: 0.9520\n",
      "Không cải thiện: 2/3\n",
      "Epoch 9/15, Train Loss: 0.0640, Val Loss: 0.1077, Val Accuracy: 0.9535\n",
      "Không cải thiện: 3/3\n",
      "Early stopping sau 9 epochs\n",
      "Evaluating MLPClassifier_TF-IDF on validation set...\n",
      "Confusion Matrix:\n",
      "[[ 74   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0  25]\n",
      " [  0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  99   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1  96   1   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  98   1   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1  99   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  93   0\n",
      "    4   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   1\n",
      "   82  13]\n",
      " [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5   1\n",
      "    7  74]]\n",
      "MLPClassifier_TF-IDF - Val Loss: 0.1077\n",
      "MLPClassifier_TF-IDF - Val Accuracy: 0.9535\n",
      "Evaluating MLPClassifier_TF-IDF on test set...\n",
      "Confusion Matrix:\n",
      "[[ 83   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1  16]\n",
      " [  0  98   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  96   1   0   1   1   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0  98   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  98   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0  99   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  99   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  99   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0  91   0\n",
      "    2   5]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  94\n",
      "    5   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   3\n",
      "   76  16]\n",
      " [ 16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   13  68]]\n",
      "MLPClassifier_TF-IDF - Test Loss: 0.1042\n",
      "MLPClassifier_TF-IDF - Test Accuracy: 0.9495\n",
      "MLPClassifier_TF-IDF saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\models/deep_learning\\MLPClassifier_TF-IDF.pth\n",
      "MLPClassifier_TF-IDF results saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\results/tables\\deep_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện và đánh giá MLP\n",
    "mlp_model = MLPClassifier(input_size, hidden_dim=128, dropout_rate=0.5, output_dim=num_classes)\n",
    "train_and_evaluate(mlp_model, \"MLPClassifier_TF-IDF\", train_loader, val_loader, test_loader, num_epochs=15, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLPBatchNormClassifier_TF-IDF...\n",
      "Epoch 1/15, Train Loss: 0.7279, Val Loss: 0.1289, Val Accuracy: 0.9605\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1289\n",
      "Epoch 2/15, Train Loss: 0.1879, Val Loss: 0.1002, Val Accuracy: 0.9610\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.1002\n",
      "Epoch 3/15, Train Loss: 0.1358, Val Loss: 0.1061, Val Accuracy: 0.9585\n",
      "Không cải thiện: 1/3\n",
      "Epoch 4/15, Train Loss: 0.1158, Val Loss: 0.1003, Val Accuracy: 0.9620\n",
      "Không cải thiện: 2/3\n",
      "Epoch 5/15, Train Loss: 0.0982, Val Loss: 0.0979, Val Accuracy: 0.9550\n",
      "Lưu mô hình tốt nhất với Val Loss: 0.0979\n",
      "Epoch 6/15, Train Loss: 0.1008, Val Loss: 0.1094, Val Accuracy: 0.9585\n",
      "Không cải thiện: 1/3\n",
      "Epoch 7/15, Train Loss: 0.0952, Val Loss: 0.1084, Val Accuracy: 0.9565\n",
      "Không cải thiện: 2/3\n",
      "Epoch 8/15, Train Loss: 0.0888, Val Loss: 0.1098, Val Accuracy: 0.9585\n",
      "Không cải thiện: 3/3\n",
      "Early stopping sau 8 epochs\n",
      "Evaluating MLPBatchNormClassifier_TF-IDF on validation set...\n",
      "Confusion Matrix:\n",
      "[[ 71   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0   0\n",
      "    0  27]\n",
      " [  0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  99   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1  96   1   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0  99   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  98   1   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1  99   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94   0\n",
      "    3   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   1\n",
      "   80  15]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   4   1\n",
      "    3  89]]\n",
      "MLPBatchNormClassifier_TF-IDF - Val Loss: 0.1098\n",
      "MLPBatchNormClassifier_TF-IDF - Val Accuracy: 0.9585\n",
      "Evaluating MLPBatchNormClassifier_TF-IDF on test set...\n",
      "Confusion Matrix:\n",
      "[[ 83   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0  16]\n",
      " [  0  98   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  97   0   0   1   1   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  98   1   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0  99   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  98   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0  99   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0  99   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0  94   0\n",
      "    1   4]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  94\n",
      "    6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   3\n",
      "   75  16]\n",
      " [  6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   12  79]]\n",
      "MLPBatchNormClassifier_TF-IDF - Test Loss: 0.1004\n",
      "MLPBatchNormClassifier_TF-IDF - Test Accuracy: 0.9565\n",
      "MLPBatchNormClassifier_TF-IDF saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\models/deep_learning\\MLPBatchNormClassifier_TF-IDF.pth\n",
      "MLPBatchNormClassifier_TF-IDF results saved to: d:\\E\\2024.2\\project_2\\Project2_20-NewsGroups\\results/tables\\deep_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện và đánh giá MLP bổ sung Batch Normalization\n",
    "mlp_batchNorm_model = MLPClassifierVariant(input_size, dropout_rate=0.5, output_dim=num_classes)\n",
    "train_and_evaluate(mlp_batchNorm_model, \"MLPBatchNormClassifier_TF-IDF\", train_loader, val_loader, test_loader, num_epochs=15, patience=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
