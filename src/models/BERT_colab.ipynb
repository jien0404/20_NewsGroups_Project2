{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3X3mUQguefvJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5Q0sZIYxeqmT"
      },
      "outputs": [],
      "source": [
        "# Thư mục làm việc chính trong Colab là /content/\n",
        "BASE_DIR = \"/content/\"\n",
        "\n",
        "# Các file dữ liệu .csv nằm trực tiếp trong BASE_DIR\n",
        "DATA_DIR = BASE_DIR # Hoặc bạn có thể ghi rõ là \"/content/\"\n",
        "\n",
        "# Định nghĩa thư mục lưu kết quả và model bên trong BASE_DIR\n",
        "# Giữ nguyên cấu trúc thư mục con như trong notebook gốc nếu muốn\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"results\", \"tables\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\", \"deep_learning\")\n",
        "\n",
        "# Tạo các thư mục này nếu chúng chưa tồn tại\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Đọc file CSV trực tiếp từ DATA_DIR (chính là /content/)\n",
        "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
        "val_df   = pd.read_csv(os.path.join(DATA_DIR, \"val.csv\"))\n",
        "test_df  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiPMEXd2fixK",
        "outputId": "9a2f0e02-38f7-4140-b4a2-034ad6870639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded labels: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
            " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
            " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
            " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
            " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
            " 'talk.politics.misc' 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_df['label_enc'] = label_encoder.fit_transform(train_df['label'])\n",
        "val_df['label_enc'] = label_encoder.transform(val_df['label'])\n",
        "test_df['label_enc'] = label_encoder.transform(test_df['label'])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "joblib.dump(label_encoder, os.path.join(MODEL_DIR, \"label_encoder.pkl\"))\n",
        "print(f\"Encoded labels: {label_encoder.classes_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb86N-Hqfkpx",
        "outputId": "f6b6e302-3fa0-435d-8f03-2a90ea7f4309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer and model...\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading BERT tokenizer and model...\")\n",
        "model_name = 'bert-base-uncased'  # Or any other BERT variant\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name)\n",
        "max_seq_length = 128  # Or adjust as needed\n",
        "\n",
        "for param in bert_model.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS0qE7IlfoYa",
        "outputId": "583b50c8-afe0-4e7d-fbc3-3dfbe8c0bf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing train data...\n",
            "Tokenizing val data...\n",
            "Tokenizing test data...\n"
          ]
        }
      ],
      "source": [
        "def tokenize_and_pad(texts, tokenizer, max_length):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'  # Returns PyTorch tensors\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "print(\"Tokenizing train data...\")\n",
        "train_input_ids, train_attention_masks = tokenize_and_pad(train_df['clean_text'].tolist(), tokenizer, max_seq_length)\n",
        "print(\"Tokenizing val data...\")\n",
        "val_input_ids, val_attention_masks = tokenize_and_pad(val_df['clean_text'].tolist(), tokenizer, max_seq_length)\n",
        "print(\"Tokenizing test data...\")\n",
        "test_input_ids, test_attention_masks = tokenize_and_pad(test_df['clean_text'].tolist(), tokenizer, max_seq_length)\n",
        "\n",
        "y_train = train_df['label_enc'].values\n",
        "y_val = val_df['label_enc'].values\n",
        "y_test = test_df['label_enc'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThBQTEIFgEBl",
        "outputId": "97fceb9f-5d62-41de-e67f-ab252a955c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: 15997 samples\n",
            "Validation set: 2000 samples\n",
            "Test set: 2000 samples\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, torch.tensor(y_train, dtype=torch.long))\n",
        "val_dataset   = TensorDataset(val_input_ids, val_attention_masks, torch.tensor(y_val, dtype=torch.long))\n",
        "test_dataset  = TensorDataset(test_input_ids, test_attention_masks, torch.tensor(y_test, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Train set: {len(train_dataset)} samples\")\n",
        "print(f\"Validation set: {len(val_dataset)} samples\")\n",
        "print(f\"Test set: {len(test_dataset)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evBMgrW0t_0C",
        "outputId": "65933b8f-08ea-47fd-8c6b-6da34a7c1b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train label distribution:\n",
            "label\n",
            "rec.autos                   0.050009\n",
            "comp.windows.x              0.050009\n",
            "sci.crypt                   0.050009\n",
            "alt.atheism                 0.050009\n",
            "rec.motorcycles             0.050009\n",
            "comp.graphics               0.050009\n",
            "talk.politics.mideast       0.050009\n",
            "comp.sys.ibm.pc.hardware    0.050009\n",
            "talk.politics.guns          0.050009\n",
            "sci.electronics             0.050009\n",
            "misc.forsale                0.050009\n",
            "sci.med                     0.050009\n",
            "sci.space                   0.050009\n",
            "rec.sport.hockey            0.050009\n",
            "comp.sys.mac.hardware       0.050009\n",
            "rec.sport.baseball          0.050009\n",
            "talk.politics.misc          0.050009\n",
            "comp.os.ms-windows.misc     0.050009\n",
            "talk.religion.misc          0.050009\n",
            "soc.religion.christian      0.049822\n",
            "Name: proportion, dtype: float64\n",
            "Val label distribution:\n",
            "label\n",
            "soc.religion.christian      0.05\n",
            "comp.sys.ibm.pc.hardware    0.05\n",
            "rec.sport.baseball          0.05\n",
            "rec.autos                   0.05\n",
            "talk.politics.guns          0.05\n",
            "comp.graphics               0.05\n",
            "sci.space                   0.05\n",
            "comp.sys.mac.hardware       0.05\n",
            "sci.med                     0.05\n",
            "talk.religion.misc          0.05\n",
            "talk.politics.mideast       0.05\n",
            "talk.politics.misc          0.05\n",
            "sci.crypt                   0.05\n",
            "comp.os.ms-windows.misc     0.05\n",
            "sci.electronics             0.05\n",
            "rec.motorcycles             0.05\n",
            "comp.windows.x              0.05\n",
            "alt.atheism                 0.05\n",
            "misc.forsale                0.05\n",
            "rec.sport.hockey            0.05\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Train label distribution:\")\n",
        "print(train_df['label'].value_counts(normalize=True))\n",
        "print(\"Val label distribution:\")\n",
        "print(val_df['label'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kg2R6_XuGfD",
        "outputId": "cb3af1bb-13fa-4a51-d49d-71d114513407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample input:\n",
            "Text: path cantaloupe srv c cmu edu magnesium club cc cmu edu news sei cmu edu ci ohio state edu zaphod mp ohio state edu sdd hp com foxtail blkhole vllyoak jp jp vllyoak resun com jeff perry newsgroups rec auto subject mustang message id date fri apr pdt reference organization private site san marcos california line jmh hopper virginia edu jeffrey hoffmeister writes article virginia edu blad got remind yes right somtime fall ford granddaddy car introducing new mega cool way fast accord driver mustang supposed streamlined looking similar mach iii concept car ford came around january wait anyone hear anything recently everything read correct ford nothing skinning existing mustang minor suspension modification picture seen indicate good job new mustang nothing cycle year old car saw picture mustang popular mechanic disappointment bombarded picture mach iii jp\n",
            "Label: rec.autos\n",
            "Tokenized IDs: tensor([ 101, 4130, 2064, 9080, 7140, 5051, 5034, 2615, 1039, 4642]) ...\n"
          ]
        }
      ],
      "source": [
        "# Kiểm tra một vài mẫu đã tokenize\n",
        "sample_idx = 0\n",
        "print(\"Sample input:\")\n",
        "print(\"Text:\", train_df['clean_text'].iloc[sample_idx])\n",
        "print(\"Label:\", train_df['label'].iloc[sample_idx])\n",
        "print(\"Tokenized IDs:\", train_input_ids[sample_idx][:10], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN0V08wgugWu",
        "outputId": "2404a8aa-cc7e-496a-c950-8cae8e877e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label_enc\n",
            "7     800\n",
            "5     800\n",
            "11    800\n",
            "0     800\n",
            "8     800\n",
            "1     800\n",
            "17    800\n",
            "3     800\n",
            "16    800\n",
            "12    800\n",
            "6     800\n",
            "13    800\n",
            "14    800\n",
            "10    800\n",
            "4     800\n",
            "9     800\n",
            "18    800\n",
            "2     800\n",
            "19    800\n",
            "15    797\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_df['label_enc'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh_U1iYovxCI",
        "outputId": "2fbcd829-faf6-44a9-b76b-ad1ce1fb5a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train NaNs: 0\n",
            "Val NaNs: 0\n",
            "Test NaNs: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Train NaNs:\", train_df['label_enc'].isna().sum())\n",
        "print(\"Val NaNs:\", val_df['label_enc'].isna().sum())\n",
        "print(\"Test NaNs:\", test_df['label_enc'].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZOEXms-vzpI",
        "outputId": "601cef95-9c8f-4dfa-c47f-b8e6f99308ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train label_enc min: 0\n",
            "Train label_enc max: 19\n",
            "Number of classes: 20\n",
            "Unique labels in train: [ 7  5 11  0  8  1 17  3 16 12  6 15 13 10  4  9 14  2 18 19]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train label_enc min:\", train_df['label_enc'].min())\n",
        "print(\"Train label_enc max:\", train_df['label_enc'].max())\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Unique labels in train:\", train_df['label_enc'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzFgJU0qv3PP",
        "outputId": "b5356672-5e08-46fb-e857-3ba8862d1edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train label distribution:\n",
            "label_enc\n",
            "0     800\n",
            "1     800\n",
            "2     800\n",
            "3     800\n",
            "4     800\n",
            "5     800\n",
            "6     800\n",
            "7     800\n",
            "8     800\n",
            "9     800\n",
            "10    800\n",
            "11    800\n",
            "12    800\n",
            "13    800\n",
            "14    800\n",
            "15    797\n",
            "16    800\n",
            "17    800\n",
            "18    800\n",
            "19    800\n",
            "Name: count, dtype: int64\n",
            "Val label distribution:\n",
            "label_enc\n",
            "0     100\n",
            "1     100\n",
            "2     100\n",
            "3     100\n",
            "4     100\n",
            "5     100\n",
            "6     100\n",
            "7     100\n",
            "8     100\n",
            "9     100\n",
            "10    100\n",
            "11    100\n",
            "12    100\n",
            "13    100\n",
            "14    100\n",
            "15    100\n",
            "16    100\n",
            "17    100\n",
            "18    100\n",
            "19    100\n",
            "Name: count, dtype: int64\n",
            "Test label distribution:\n",
            "label_enc\n",
            "0     100\n",
            "1     100\n",
            "2     100\n",
            "3     100\n",
            "4     100\n",
            "5     100\n",
            "6     100\n",
            "7     100\n",
            "8     100\n",
            "9     100\n",
            "10    100\n",
            "11    100\n",
            "12    100\n",
            "13    100\n",
            "14    100\n",
            "15    100\n",
            "16    100\n",
            "17    100\n",
            "18    100\n",
            "19    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Train label distribution:\")\n",
        "print(train_df['label_enc'].value_counts().sort_index())\n",
        "\n",
        "print(\"Val label distribution:\")\n",
        "print(val_df['label_enc'].value_counts().sort_index())\n",
        "\n",
        "print(\"Test label distribution:\")\n",
        "print(test_df['label_enc'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5TG9wSWQgGWm"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, output_dim, dropout_rate=0.1):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        # Sử dụng biểu diễn token [CLS]\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "        x = self.dropout(cls_output)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VKwUwSmVgIaV"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=3, patience=1, model_name=\"Model\"):\n",
        "    model = model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - {model_name}\", leave=False)\n",
        "\n",
        "        for input_ids, attention_mask, y_batch in progress_bar: #unpack tensors\n",
        "            input_ids, attention_mask, y_batch = input_ids.to(device), attention_mask.to(device), y_batch.to(device) #Move data to device\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "            progress_bar.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        val_predictions = []\n",
        "        val_true_labels = []\n",
        "        total_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, y_val_batch in val_loader: #unpack tensors\n",
        "                input_ids, attention_mask, y_val_batch = input_ids.to(device), attention_mask.to(device), y_val_batch.to(device) #Move data to device\n",
        "                val_outputs = model(input_ids, attention_mask)\n",
        "                loss = criterion(val_outputs, y_val_batch)\n",
        "                total_val_loss += loss.item()\n",
        "                _, val_predicted = torch.max(val_outputs, 1)\n",
        "                val_total += y_val_batch.size(0)\n",
        "                val_correct += (val_predicted == y_val_batch).sum().item()\n",
        "                val_predictions.extend(val_predicted.cpu().numpy())\n",
        "                val_true_labels.extend(y_val_batch.cpu().numpy())\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_report = classification_report(val_true_labels, val_predictions, output_dict=True, zero_division=0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f} - Val Loss: {avg_val_loss:.4f} - Val Acc: {val_acc:.2f}% - {model_name}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_val_acc = val_acc\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1} - {model_name}\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}% - {model_name}\")\n",
        "    return model, best_val_acc/100, val_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "D80SQQG0gJo1"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, model_name=\"Model\"):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, y_batch in test_loader: #unpack tensors\n",
        "            input_ids, attention_mask, y_batch = input_ids.to(device), attention_mask.to(device), y_batch.to(device) #Move data to device\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    test_accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, output_dict=True, zero_division=0)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}% - {model_name}\")\n",
        "    print(classification_report(true_labels, predictions))\n",
        "    return test_accuracy, report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "k-JyZNNPgNZ2"
      },
      "outputs": [],
      "source": [
        "def save_results(model_name, test_accuracy, report, val_accuracy, val_report):\n",
        "    results = {\n",
        "        \"Model\": model_name,\n",
        "        \"Test_Accuracy\": test_accuracy,\n",
        "        \"Test_Precision\": report['weighted avg']['precision'],\n",
        "        \"Test_Recall\": report['weighted avg']['recall'],\n",
        "        \"Test_F1-Score\": report['weighted avg']['f1-score'],\n",
        "        \"Val_Accuracy\": val_accuracy,\n",
        "        \"Val_Precision\": val_report['weighted avg']['precision'],\n",
        "        \"Val_Recall\": val_report['weighted avg']['recall'],\n",
        "        \"Val_F1-Score\": val_report['weighted avg']['f1-score']\n",
        "    }\n",
        "    results_df = pd.DataFrame([results])\n",
        "    results_file = os.path.join(RESULTS_DIR, \"deep_models_results.csv\")\n",
        "    if not os.path.exists(results_file):\n",
        "        results_df.to_csv(results_file, index=False, header=True)\n",
        "    else:\n",
        "        results_df.to_csv(results_file, index=False, header=False, mode='a')\n",
        "    print(f\"Deep Learning results saved to: {results_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOKC_pJ1gPTG",
        "outputId": "a5ccd17b-dca3-4123-8542-17e6ff64fc8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Loss: 0.3392 - Val Loss: 0.0791 - Val Acc: 97.05% - BERT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/3 - Loss: 0.0749 - Val Loss: 0.0592 - Val Acc: 97.10% - BERT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/3 - Loss: 0.0684 - Val Loss: 0.0576 - Val Acc: 97.10% - BERT\n",
            "Best Validation Accuracy: 97.10% - BERT\n",
            "Test Accuracy: 0.97% - BERT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.83      0.91       100\n",
            "           1       0.99      1.00      1.00       100\n",
            "           2       1.00      0.96      0.98       100\n",
            "           3       1.00      1.00      1.00       100\n",
            "           4       1.00      1.00      1.00       100\n",
            "           5       0.98      0.99      0.99       100\n",
            "           6       0.99      1.00      1.00       100\n",
            "           7       1.00      0.98      0.99       100\n",
            "           8       1.00      1.00      1.00       100\n",
            "           9       1.00      1.00      1.00       100\n",
            "          10       1.00      1.00      1.00       100\n",
            "          11       0.99      1.00      1.00       100\n",
            "          12       0.98      1.00      0.99       100\n",
            "          13       0.99      1.00      1.00       100\n",
            "          14       1.00      1.00      1.00       100\n",
            "          15       1.00      1.00      1.00       100\n",
            "          16       0.91      0.99      0.95       100\n",
            "          17       0.97      0.99      0.98       100\n",
            "          18       1.00      0.75      0.86       100\n",
            "          19       0.75      0.97      0.84       100\n",
            "\n",
            "    accuracy                           0.97      2000\n",
            "   macro avg       0.98      0.97      0.97      2000\n",
            "weighted avg       0.98      0.97      0.97      2000\n",
            "\n",
            "Deep Learning results saved to: /content/results/tables/deep_models_results.csv\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Initialise Models\n",
        "bert_model_classifier = BERTClassifier(bert_model, num_classes)\n",
        "\n",
        "#Define optimizers and Criterion\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "bert_optimizer = optim.Adam(bert_model_classifier.parameters(), lr=3e-5)\n",
        "\n",
        "#Run Models\n",
        "bert_model_classifier, val_accuracy_bert, val_report_bert = train_model(bert_model_classifier, train_loader, val_loader, criterion, bert_optimizer, epochs=3, model_name=\"BERT\")\n",
        "test_accuracy_bert, report_bert = evaluate_model(bert_model_classifier, test_loader, model_name=\"BERT\")\n",
        "save_results(\"BERTClassifier\", test_accuracy_bert, report_bert, val_accuracy_bert, val_report_bert)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
